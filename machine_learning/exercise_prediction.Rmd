---
title: "Prediction on how a weight lifting exercise is done"
author: "David Conejero"
date: "23 de agosto de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warnings = FALSE)
```


## Overview

In this document we are going to define a model to predict how a weight 
lifting exercise is being done. In order to do that we are going to use the database created by the [Human Activity Recognition at Groupware@LES](http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har).

From the data, the most relevant features have been selected, then the data has been splitted between train and test, and different models have been created and tested. After the evaluation of the different models it has been detected that the RandomForest was the one which would predict better the kind of performance the user has done with more than 99% of Accuracy.

## Preparation

Libraries being used:

```{r libraries, message=FALSE}
library(caret)
library(rattle)
library(parallel)
library(doParallel)
library(gridExtra)
library(dplyr)
```

Downloading data

```{r download, cache=TRUE}
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                   na.strings = c("NA","","#DIV/0!"))
testing<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
          na.strings = c("NA","","#DIV/0!"))
```

## Feature selection

After a visual inspection on the data, the first features were removed, because they did not provide relevant information to the prediction. Features with almost values were also discarded.
Finally, it was checked if any other value of the feature list was not providing any value.

```{r cleaning}
# Remove unnecessary features
t<-training[,-1:-7]
# Remove features with no values
t<-t[, colSums(is.na(t)) < 1900]
# Check if there are other features that should be removed
nearZero<-nearZeroVar(t, saveMetrics = TRUE)

```

After visual inspection of nearZero vector, it was checked that no more features should be removed.
And we finally get 53 features and the predicted value.

Highly correlated features will also be removed.

```{r correlated}
# Choosing features
c<-cor(t[,-length(t)])

# Cutoff has been set to 0.8, since there are too many features and it may be difficult to compute models
correlated<-findCorrelation(c, cutoff=0.8)
t<-t[, -correlated]

```

With this final selection, only 40 features remain.

## Database split

In order to ensure the independece of the study, training dataset is splitted for training the data model (train_data) and testing it (test_data). Testing test will be kept untouched.

```{r split}
set.seed(1234)
inTrain<-createDataPartition(training$classe, p = 0.70, list = FALSE)
train_data<-t[inTrain,]
test_data<-t[-inTrain,]
```

## Fitting models

Several models will be created to test which one predicts best how the exercise is being done:

In order to accelerate the training process:

```{r parallel}
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
```

### Tree

A Tree model is fitted to the training data
```{r tree, cache=TRUE, message=FALSE}
tree<-train(classe ~., data=train_data, method="rpart")

tree_predict<-predict(tree,test_data)
tree_cm<-confusionMatrix(tree_predict,test_data$classe)
```

We can see what would be the decission Tree in this scenario:

```{r plot_tree}
fancyRpartPlot(tree$finalModel, sub = "")
```


## GBM

```{r gbm, cache=TRUE, message=FALSE}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           allowParallel = TRUE)
gbm<-train(classe ~., data=train_data, method="gbm", 
           trControl = fitControl)
gbm_predict<-predict(gbm,test_data)
gbm_cm<-confusionMatrix(gbm_predict,test_data$classe)
```


## RandomForest

```{r RandomForest, cache=TRUE, message=FALSE}

rf<-train(classe ~., data=train_data, preprocess=c("center","scale"), 
          method="rf",trControl = fitControl)

rf_predict<-predict(rf,test_data)
rf_cm<-confusionMatrix(rf_predict,test_data$classe)

```

## LDA

```{r lda, cache=TRUE, message=FALSE}
lda<-train(classe ~., data=train_data, preprocess=c("center","scale"),
           method="lda",trControl = fitControl)
lda_predict<-predict(lda,test_data)
lda_cm<-confusionMatrix(lda_predict,test_data$classe)
```

# SVM

```{r svm, cache=TRUE, message=FALSE}
ctrl <- trainControl(method = "repeatedcv", repeats = 10)
svm <- train(classe~., data=train_data, preprocess=c("center","scale"), 
             method = "svmLinear", trControl = ctrl)

svm_predict<-predict(svm,test_data)
svm_cm<-confusionMatrix(svm_predict,test_data$classe)
```

## Confusion Matrix

Checking the confusion matrix for the different algorithms used:

```{r plot, echo=FALSE}
rf_cm_table <- as.data.frame(rf_cm$table) %>% 
        mutate(Reference=factor(Reference), Reference=factor(Reference, rev(levels(Reference))))
rf_plot <- ggplot(data =  rf_cm_table, mapping = aes(x = Prediction, y = Reference)) +
        geom_tile(aes(fill = Freq), colour = "gray") +
        geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
        scale_fill_gradient(low = "white", high = "red") +
        xlab("Predicted Class") + ylab("Actual Class") + 
        ggtitle("Confusion Matrix for the RF Model") +
        theme_bw() + theme(legend.position = "right", plot.title = element_text(hjust = 0.5))

rf_cm_table <- as.data.frame(rf_cm$table) %>% 
        mutate(Reference=factor(Reference), Reference=factor(Reference, rev(levels(Reference))))
rf_plot <- ggplot(data =  rf_cm_table, mapping = aes(x = Prediction, y = Reference)) +
        geom_tile(aes(fill = Freq), colour = "gray") +
        geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
        scale_fill_gradient(low = "white", high = "red") +
        xlab("Predicted Class") + ylab("Actual Class") + 
        ggtitle("Confusion Matrix for the RF Model") +
        theme_bw() + theme(legend.position = "right", plot.title = element_text(hjust = 0.5))

tree_cm_table <- as.data.frame(tree_cm$table) %>% 
        mutate(Reference=factor(Reference), Reference=factor(Reference, rev(levels(Reference))))
tree_plot <- ggplot(data =  tree_cm_table, mapping = aes(x = Prediction, y = Reference)) +
        geom_tile(aes(fill = Freq), colour = "gray") +
        geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
        scale_fill_gradient(low = "white", high = "red") +
        xlab("Predicted Class") + ylab("Actual Class") + 
        ggtitle("Confusion Matrix for the Tree Model") +
        theme_bw() + theme(legend.position = "right", plot.title = element_text(hjust = 0.5))

gbm_cm_table <- as.data.frame(gbm_cm$table) %>% 
        mutate(Reference=factor(Reference), Reference=factor(Reference, rev(levels(Reference))))
gbm_plot <- ggplot(data =  gbm_cm_table, mapping = aes(x = Prediction, y = Reference)) +
        geom_tile(aes(fill = Freq), colour = "gray") +
        geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
        scale_fill_gradient(low = "white", high = "red") +
        xlab("Predicted Class") + ylab("Actual Class") + 
        ggtitle("Confusion Matrix for the GBM Model") +
        theme_bw() + theme(legend.position = "right", plot.title = element_text(hjust = 0.5))

svm_cm_table <- as.data.frame(svm_cm$table) %>% 
        mutate(Reference=factor(Reference), Reference=factor(Reference, rev(levels(Reference))))
svm_plot <- ggplot(data =  svm_cm_table, mapping = aes(x = Prediction, y = Reference)) +
        geom_tile(aes(fill = Freq), colour = "gray") +
        geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
        scale_fill_gradient(low = "white", high = "red") +
        xlab("Predicted Class") + ylab("Actual Class") + 
        ggtitle("Confusion Matrix for the SVM Model") +
        theme_bw() + theme(legend.position = "right", plot.title = element_text(hjust = 0.5))

lda_cm_table <- as.data.frame(lda_cm$table) %>% 
        mutate(Reference=factor(Reference), Reference=factor(Reference, rev(levels(Reference))))
lda_plot <- ggplot(data =  lda_cm_table, mapping = aes(x = Prediction, y = Reference)) +
        geom_tile(aes(fill = Freq), colour = "gray") +
        geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
        scale_fill_gradient(low = "white", high = "red") +
        xlab("Predicted Class") + ylab("Actual Class") + 
        ggtitle("Confusion Matrix for the LDA Model") +
        theme_bw() + theme(legend.position = "right", plot.title = element_text(hjust = 0.5))

grid.arrange(tree_plot, gbm_plot, lda_plot, svm_plot, ncol=2)

```

```{r plot_rf, echo=FALSE}
rf_plot
```

As it can bee seen the correlation is almost perfect for RandomForest, and that's the model used on the exercise.

```{r rf_cm}

rf_cm$overall

```

Since the test is incorrelated to the trainning set, and only it has been used to the selection of the model, but it has not been used to improve the model, 99% accuracy could be defined as the out of sample error.

